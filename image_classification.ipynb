{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN6jpa1i/fjTHijK1ceNJhK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lee-thien-tuyen/image-classification/blob/main/image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classification images: Clean/ Dirtyed road"
      ],
      "metadata": {
        "id": "u-C8NFmvyo7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load file dataset from github"
      ],
      "metadata": {
        "id": "2zzPENrkQbTw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE32FHrUrZo8"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/lee-thien-tuyen/image-classification.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import library"
      ],
      "metadata": {
        "id": "P4gIa-MwQrvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import cv2\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "kXAVPW39rg8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data, formatting"
      ],
      "metadata": {
        "id": "Dr7QBHpOQwnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"image-classification/data_set/metadata.csv\")\n",
        "dataset.head(5)"
      ],
      "metadata": {
        "id": "IV3Cd4mfsTB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "FbjTSO5ccmMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.describe()"
      ],
      "metadata": {
        "id": "uV-WfaVkcvXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ('clean','dirty')\n",
        "num_classes = len(class_names)\n",
        "\n",
        "img_size = (128,128,3)\n",
        "print(f'{num_classes} classes: {class_names}')\n",
        "print(\"image size:\",img_size)"
      ],
      "metadata": {
        "id": "HDbLqfEIbe-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.iloc[8][1]"
      ],
      "metadata": {
        "id": "uf0lLSI3mMz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/image-classification/data_set/Images/Images'\n",
        "labels = []\n",
        "images = []\n",
        "for image in dataset.iloc:\n",
        "    images.append(np.asarray(cv2.resize(cv2.imread(image_path + '/' + image[0], cv2.IMREAD_COLOR), img_size[0:2])[:, :, ::-1]))\n",
        "\n",
        "    # labels will be in the form of a vector: [0, 1] or [1, 0] means that one hot coding\n",
        "    label = np.zeros(num_classes)\n",
        "    label[image[1]] = 1\n",
        "    labels.append(label)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "images = np.asarray(images)\n",
        "print(\"labels shape:\", labels.shape)\n",
        "print(\"images shape:\", images.shape)\n",
        "\n",
        "plt.imshow(images[1])"
      ],
      "metadata": {
        "id": "dNA_OwwrdhKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualisation data"
      ],
      "metadata": {
        "id": "y8EEgAuiTNKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display 16 pictures from the dataset\n",
        "fig, axs = plt.subplots(4, 4, figsize=(10, 10))\n",
        "\n",
        "for x in range(4):\n",
        "    for y in range(4):\n",
        "        i = np.random.randint(0, len(images))\n",
        "\n",
        "        axs[x][y].imshow(images[i])\n",
        "\n",
        "        # delete x and y ticks and set x label as picture label\n",
        "        axs[x][y].set_xticks([])\n",
        "        axs[x][y].set_yticks([])\n",
        "        axs[x][y].set_xlabel(class_names[np.argmax(labels[i])])"
      ],
      "metadata": {
        "id": "feam5H4BMhEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Train/Validation"
      ],
      "metadata": {
        "id": "ARxciIeyTWRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_val,y_train,y_val = train_test_split(images, labels,test_size = 0.2,random_state = 42)\n",
        "\n",
        "print(f\"train images shape: {x_train.shape}\\ntrain labels shape: {y_train.shape}\\n\")\n",
        "print(f\"validation images shape: {x_val.shape}\\nvalidation labels shape: {y_val.shape}\\n\")"
      ],
      "metadata": {
        "id": "scO3ZpqnMiUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data augmentation"
      ],
      "metadata": {
        "id": "CH4lr1_GUK2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageDataGenerator for train images\n",
        "train_images_generator = tf.keras.preprocessing.image.ImageDataGenerator(shear_range=0.3,\n",
        "                                                                         rotation_range=15,\n",
        "                                                                         zoom_range=0.3,\n",
        "                                                                         vertical_flip=True,\n",
        "                                                                         horizontal_flip=True,rescale = 1./255)\n",
        "train_images_generator = train_images_generator.flow(x_train,y_train)\n",
        "\n",
        "# ImageDataGenerator for validation images\n",
        "val_images_generator = tf.keras.preprocessing.image.ImageDataGenerator(shear_range=0.3,\n",
        "                                                                         rotation_range=15,\n",
        "                                                                         zoom_range=0.3,\n",
        "                                                                         vertical_flip=True,\n",
        "                                                                         horizontal_flip=True,rescale = 1./255)\n",
        "val_images_generator = val_images_generator.flow(x_val,y_val)\n",
        "\n"
      ],
      "metadata": {
        "id": "K8_wU8yMT2dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNNs model"
      ],
      "metadata": {
        "id": "mJFxv_RLV6ZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_model():\n",
        "    cnn_model = tf.keras.Sequential([\n",
        "\n",
        "    # Convolutional block 1 and Input\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same',input_shape = img_size[:]),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "    # Convolutional block 2\n",
        "    tf.keras.layers.Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
        "    tf.keras.layers.Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "    # Convolutional block 3\n",
        "    tf.keras.layers.Conv2D(256, (2, 2), activation='relu', padding='same'),\n",
        "    tf.keras.layers.Conv2D(256, (2, 2), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "\n",
        "    # Dense block\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    # optimizer = tf.keras.optimizers.Adam(\n",
        "    #                             learning_rate= 0.001,\n",
        "    #                             beta_1 = 0.9,\n",
        "    #                             beta_2 = 0.999,\n",
        "    #                             epsilon = 1e-07,\n",
        "    #                             name = 'Adam')\n",
        "\n",
        "    cnn_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return cnn_model"
      ],
      "metadata": {
        "id": "53S5EhQ5NBMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lottery Ticket Hypothesis Realizing\n",
        "About lottery ticket hypotesis - https://arxiv.org/abs/1803.03635"
      ],
      "metadata": {
        "id": "BXKGZ231eXep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# my lottery ticket hypotesis realization\n",
        "min_loss = 10\n",
        "for seed in np.linspace(1, 257654, 15).astype(int):\n",
        "    tf.random.set_seed(seed)\n",
        "    cnn_model = get_model()\n",
        "\n",
        "    loss = cnn_model.fit(train_images_generator, epochs=1, verbose=1, steps_per_epoch=189).history['loss'][0]\n",
        "    if loss < min_loss:\n",
        "        min_loss = loss\n",
        "        best_model = cnn_model\n",
        "\n",
        "print(f'\\n\\nmin loss: {min_loss}', best_model.summary())"
      ],
      "metadata": {
        "id": "DCOSBs4qeevu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Results"
      ],
      "metadata": {
        "id": "H1tTdaQVPQy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating ModelChecpoint callback\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint('cnn_model/model{epoch:02d}')\n",
        "\n",
        "history = best_model.fit(train_images_generator, epochs=200, verbose=1, validation_data=val_images_generator, callbacks=[checkpoint_callback])\n"
      ],
      "metadata": {
        "id": "GgfbnTcyPTsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "minimum val_loss: 0.0273 - val_accuracy: 1.0000 | epoch 192\n"
      ],
      "metadata": {
        "id": "nyLd-A6jbuj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading best model\n",
        "cnn_model = tf.keras.models.load_model('cnn_model/model195')"
      ],
      "metadata": {
        "id": "AwRA0wRrbfLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy and Loss Plot"
      ],
      "metadata": {
        "id": "y8RbhbyTcLju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(accuracy))"
      ],
      "metadata": {
        "id": "zY3dMSlNcQdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(epochs, accuracy, label='Training Accuracy')\n",
        "plt.plot(epochs, loss, label='Training Loss')\n",
        "plt.legend()\n",
        "plt.title('Training Accuracy and Loss')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Validation Accuracy and Loss')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DBKVvbX5cVlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "JDPVEG9_cX6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(12, 4, figsize=(12, 12))\n",
        "\n",
        "i = 0\n",
        "for x in range(12):\n",
        "    for y in range(4):\n",
        "        prediction = cnn_model.predict(x_val[i][None, ...], verbose=0)[0]\n",
        "\n",
        "        axs[x][y].set_xticks([])\n",
        "        axs[x][y].set_yticks([])\n",
        "\n",
        "        if np.argmax(prediction) != np.argmax(y_val[i]):\n",
        "            axs[x][y].set_xlabel(f'prediction: {class_names[np.argmax(prediction)]} | label: {class_names[np.argmax(y_val[i])]}', color='red')\n",
        "        else:\n",
        "            axs[x][y].set_xlabel(f'prediction: {class_names[np.argmax(prediction)]} | label: {class_names[np.argmax(y_val[i])]}')\n",
        "\n",
        "        axs[x][y].imshow(x_val[i])\n",
        "\n",
        "        i += 1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h_ayUIpnnnrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.save_weights('cleanroad_model.h5')"
      ],
      "metadata": {
        "id": "dZQJoIT7ddL2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}